<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title></title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Homepage</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="index_CHN.html">中文主页</a></div>
<div class="menu-item"><a href="Publication.html">Publication&nbsp;(by&nbsp;year)</a></div>
<div class="menu-item"><a href="Publication_topic.html">Publication&nbsp;(by&nbsp;topic)</a></div>
<div class="menu-item"><a href="Teaching.html">Teaching</a></div>
</td>
<td id="layout-content">
<p><br /></p>
<h1>Mathematical Foundation of Data Science and Machine Learning</h1>
<p><b>This website is under construction. Course information is subject to change.</b></p>
<p><b>Course Objective:</b>  An introduction to various topics of modern data science and machine learning.
Prerequisites include calculus, linear algebra, and probability theory at the undergraduate level. </p>
<p><b>Instructor:</b> Shuyang LING (sl3635@nyu.edu)</p>
<p><b>Lecture Time/Location:</b> 1:15PM - 2:30PM on Mondays and Wednesdays, PDNG 213</p>
<p><b>Discussion/Recitation:</b> 1:15PM - 2:30PM on Fridays, PDNG 213. This part will be used to discuss course projects.</p>
<p><b>Office hours:</b> Room 1162-3</p>
<ul>
<li><p>Time TBD</p>
</li>
</ul>
<p>* We will meet on Zoom due to the shutdown of academic building. </p>
<p><b>Textbook:</b> The course consists of various topics. I will provide lecture notes and reading materials throughout of the course. Here are several references:</p>
<ul>
<li><p><a href="https://www.cs.cornell.edu/jeh/book.pdf"><i>Foundations of Data Science</i></a> by A. Blum, J. Hopcroft, and R. Kannan.</p>
</li>
<li><p><a href="https://www.cambridge.org/core/books/highdimensional-probability/797C466DA29743D2C8213493BD2D2102"><i>High-Dimensional Probability: An Introduction with Applications in Data Science</i></a> by R. Vershynin. </p>
</li>
<li><p><a href="https://www.cambridge.org/core/books/highdimensional-statistics/8A91ECEEC38F46DAB53E9FF8757C7A4E"><i>High-Dimensional Statistics: A Non-Asymptotic Viewpoint</i></a> by M. Wainwright.</p>
</li>
<li><p><a href="https://link.springer.com/book/10.1007/978-0-8176-4948-7"><i>A Mathematical Introduction to Compressive Sensing</i></a> by S. Foucart and H. Rauhut.</p>
</li>
<li><p><a href="https://link.springer.com/book/10.1007/978-0-387-84858-7"><i>The Elements of Statistical Learning: Data Mining, Inference and Prediction</i></a> by T. Hastie, R. Tibshirani, and J. Friedman.</p>
</li>
<li><p><a href="https://people.math.ethz.ch/~abandeira/TenLecturesFortyTwoProblems.pdf"><i>Ten Lectures and Forty-Two Open Problems in the Mathematics of Data Science</i></a> by A.S. Bandeira</p>
</li>
<li><p><a href="https://github.com/yao-lab/yao-lab.github.io/blob/master/book_datasci.pdf"><i>A Mathematical Introduction to Data Analysis</i></a> by Y. Yao</p>
</li>
<li><p><a href="https://www.cs.yale.edu/homes/spielman/561/"><i>Spectral graph theory</i></a> by D. Spielman</p>
</li>
</ul>
<p><b>Grading policy:</b> </p>
<ul>
<li><p>Homework 40%</p>
</li>
<li><p>Final project 60% </p>
</li>
</ul>
<p><b>Homework</b></p>
<table id="Homework">
<tr class="r1"><td class="c1"></td><td class="c2">Due date</td></tr>
<tr class="r2"><td class="c1"><a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-SPRING20-HW1.pdf">Homework 1</a> </td><td class="c2"> Feb 27 </td></tr>
<tr class="r3"><td class="c1"><a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-SPRING20-HW2.pdf">Homework 2</a> </td><td class="c2"> Mar 10 </td></tr>
<tr class="r4"><td class="c1"><a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-SPRING20-HW3.pdf">Homework 3</a> </td><td class="c2"> Mar 19 </td></tr>
<tr class="r5"><td class="c1"><a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-SPRING20-HW4.pdf">Homework 4</a> </td><td class="c2"> Apr 9 </td></tr>
<tr class="r6"><td class="c1"><a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-SPRING20-HW5.pdf">Homework 5</a> </td><td class="c2"> May 7 </td></tr>
<tr class="r7"><td class="c1"><a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-SPRING20-HW6.pdf">Homework 6</a> </td><td class="c2"> May 15 
</td></tr></table>
<p>Late homework will not be accepted. Only a subset of problems will be graded. </p>
<p><b>Course schedule:</b>
The slides will be updated after each lecture. It is the first time this course is taught. The notes inevitably contain typos.</p>
<table id="Course schedule">
<tr class="r1"><td class="c1">Date </td><td class="c2">  Topics </td><td class="c3"> Lecture notes </td></tr>
<tr class="r2"><td class="c1">Feb 17 </td><td class="c2"> SVD </td><td class="c3"> <a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-Lecture-1-2-3-PCASVD.pdf">Lecture 1-3</a> </td></tr>
<tr class="r3"><td class="c1">Feb 19 </td><td class="c2"> SVD </td><td class="c3"> </td></tr>
<tr class="r4"><td class="c1">Feb 24 </td><td class="c2"> PCA </td><td class="c3"> </td></tr>
<tr class="r5"><td class="c1">Feb 26 </td><td class="c2"> High-dim geometry </td><td class="c3"> <a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-Lecture-4-5-highdim.pdf">Lecture 4-5</a> </td></tr>
<tr class="r6"><td class="c1">Mar 2  </td><td class="c2"> High-dim geometry </td><td class="c3"> </td></tr>
<tr class="r7"><td class="c1">Mar 4 </td><td class="c2"> k-means </td><td class="c3"> <a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-Lecture-6-kmeans.pdf">Lecture 6</a> </td></tr>
<tr class="r8"><td class="c1">Mar 9 </td><td class="c2"> Spectral clustering </td><td class="c3"> <a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-Lecture-7-8-spectral.pdf">Lecture 7-8</a> </td></tr>
<tr class="r9"><td class="c1">Mar 11 </td><td class="c2"> Graph Laplacian </td><td class="c3"> </td></tr>
<tr class="r10"><td class="c1">Mar 16 </td><td class="c2"> Ratio/normalized cut</td><td class="c3"> <a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-Lecture-9-graphcut.pdf">Lecture 9</a> </td></tr>
<tr class="r11"><td class="c1">Mar 18 </td><td class="c2"> Diffusion maps</td><td class="c3"><a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-Lecture-10-11-dmap.pdf">Lecture 10-11</a> </td></tr>
<tr class="r12"><td class="c1">Mar 21 </td><td class="c2"> Diffusion maps </td><td class="c3">  </td></tr>
<tr class="r13"><td class="c1">Mar 23 </td><td class="c2"> t-SNE </td><td class="c3"> <a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-Lecture-12-tsne.pdf">Lecture 12</a> </td></tr>
<tr class="r14"><td class="c1">Mar 25 </td><td class="c2"> Maxcut </td><td class="c3"> <a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-Lecture-13-14-maxcut.pdf">Lecture 13-14</a> </td></tr>
<tr class="r15"><td class="c1">Mar 30 </td><td class="c2"> Maxcut </td><td class="c3"> </td></tr>
<tr class="r16"><td class="c1">Apr 1 </td><td class="c2"> Convex relaxation of graph cut </td><td class="c3"> <a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-Lecture-15-mincut.pdf">Lecture 15</a> </td></tr>
<tr class="r17"><td class="c1">Apr 6 </td><td class="c2"> Stochastic block model </td><td class="c3"> <a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-Lecture-16-SBM-Spectral.pdf">Lecture 16</a> </td></tr>
<tr class="r18"><td class="c1">Apr 8 </td><td class="c2"> Concentration inequality </td><td class="c3"> <a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-Lecture-17-18-Concentration.pdf">Lecture 17-18</a> </td></tr>
<tr class="r19"><td class="c1">Apr 11 </td><td class="c2"> Concentration inequality </td><td class="c3"> </td></tr>
<tr class="r20"><td class="c1">Apr 13 </td><td class="c2"> Matrix concentration </td><td class="c3"> <a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-Lecture-19-Matrix-Inequality.pdf">Lecture 19</a> </td></tr>
<tr class="r21"><td class="c1">Apr 15 </td><td class="c2"> Johnson-Lindenstrauss Lemma </td><td class="c3"> <a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-Lecture-20-JL.pdf">Lecture 20</a> </td></tr>
<tr class="r22"><td class="c1">Apr 20 </td><td class="c2"> Matrix multiplication via random sampling </td><td class="c3"> <a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-Lecture-21-22-MM.pdf">Lecture 21-22</a> </td></tr>
<tr class="r23"><td class="c1">Apr 22 </td><td class="c2"> Matrix multiplication via random sampling </td><td class="c3"> </td></tr>
<tr class="r24"><td class="c1">Apr 27 </td><td class="c2"> Graph sparsification </td><td class="c3"> <a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-Lecture-23-GS.pdf">Lecture 23</a> </td></tr>
<tr class="r25"><td class="c1">Apr 29 </td><td class="c2"> Compressive sensing </td><td class="c3"> <a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-Lecture-24-25-CS.pdf">Lecture 24-25</a> </td></tr>
<tr class="r26"><td class="c1">May 4 </td><td class="c2"> Compressive sensing </td><td class="c3"> </td></tr>
<tr class="r27"><td class="c1">May 6 </td><td class="c2"> Low-rank model </td><td class="c3"> <a href="MATH-SHU-236-2020-SPRING/MATH-SHU-236-Lecture-26-27-LR.pdf">Lecture 26-27</a> </td></tr>
<tr class="r28"><td class="c1">May 11 </td><td class="c2"> Low-rank model </td><td class="c3"> </td></tr>
<tr class="r29"><td class="c1">May 13 </td><td class="c2"> Project presentation </td><td class="c3"> 
</td></tr></table>
<div id="footer">
<div id="footer-text">
Page generated 2020-09-14 18:17:52 CST, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
