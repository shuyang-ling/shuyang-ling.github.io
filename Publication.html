<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title></title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Homepage</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="index_CHN.html">中文主页</a></div>
<div class="menu-item"><a href="Bio.html">About&nbsp;me</a></div>
<div class="menu-item"><a href="Publication.html" class="current">Publication&nbsp;(by&nbsp;year)</a></div>
<div class="menu-item"><a href="Publication_topic.html">Publication&nbsp;(by&nbsp;topic)</a></div>
<div class="menu-item"><a href="Teaching.html">Teaching</a></div>
<div class="menu-item"><a href="Group.html">Group</a></div>
<div class="menu-item"><a href="Talks.html">Talks</a></div>
</td>
<td id="layout-content">
<p><br /></p>
<h1>Publication (by year)</h1>
<h2>Submitted</h2>
<ol>
<li><p><b>Beyond unconstrained features: neural collapse for shallow neural networks with general data</b>. 
<br /> W. Hong and <b>S. Ling</b>, submitted, 2024. <a href="https://arxiv.org/pdf/2409.01832">(arXiv version)</a>.</p>
</li>
<li><p><b>Uncertainty quantification of spectral estimator and MLE for orthogonal group synchronization</b>. 
<br /> Z. S. Zhong and <b>S. Ling</b>, submitted, 2024. <a href="https://arxiv.org/pdf/2408.05944">(arXiv version)</a>.</p>
</li>
<li><p><b>On the exactness of SDP relaxation for quadratic assignment problem</b>. 
<br /> <b>S. Ling</b>, submitted, 2024. <a href="https://arxiv.org/abs/2408.05942">(arXiv version)</a>.</p>
</li>
<li><p><b>Cross entropy versus label smoothing: a neural collapse perspective</b>. 
<br />
L. Guo, K. Ross, Z. Zhao, A. George, <b>S. Ling</b>, Y. Xu, Z. Dong, submitted, 2024. <a href="https://arxiv.org/abs/arXiv:2402.03979.pdf">(arXiv version)</a>.</p>
</li>
<li><p><b>Local geometry determines global landscape in low-rank factorization for synchronization</b>. <br />
<b>S. Ling</b>, submitted, 2023. <a href="https://arxiv.org/abs/2311.18670.pdf">(arXiv version)</a><a href="https://youtu.be/__b2HF1MSxo?si=w_NEPnisir4uxdqL">(Talking recording by IMA at UMN, on Youtube)</a>.</p>
</li>
<li><p><b>On the critical coupling of the finite Kuramoto model on dense networks</b>.<br /> <b>S. Ling</b>,  submitted, 2020. <a href="https://arxiv.org/pdf/2004.03202.pdf">(arXiv version)</a></p>
</li>
</ol>
<h2>Journal Publications</h2>
<ol>
<li><p><b>Generalized orthogonal Procrustes problem under arbitrary adversaries</b>.<br /> <b>S. Ling</b>, <i>SIAM Journal on Matrix Analysis and Applications, to appear</i>, 2024. <a href="https://arxiv.org/abs/2106.15493.pdf">(arXiv version)</a>.</p>
</li>
<li><p><b>Improved theoretical guarantee for rank aggregation via spectral method</b>. <br /> Z. S. Zhong, <b>S. Ling</b>, <i>Information and Inference: A Journal of the IMA</i>, 13(3):1-36, 2024. <a href="https://arxiv.org/abs/2309.03808.pdf">(arXiv version)</a><a href="https://academic.oup.com/imaiai/article/13/3/iaae020/7731529">(Final)</a>.</p>
</li>
<li><p><b>Neural collapse for unconstrained feature model under cross-entropy loss with imbalanced data</b>. <br /> W. Hong, <b>S. Ling</b>, <i>Journal of Machine Learning Research</i> 25(192):1-48, 2024. <a href="https://arxiv.org/abs/2309.09725.pdf">(arXiv version)</a><a href="https://www.jmlr.org/papers/v25/23-1215.html">(Journal)</a><a href="https://youtu.be/UieOBeTokqM?si=ssmwvM74BD0g8SDZ">(Talk recording on Youtube)</a>.</p>
</li>
<li><p><b>Near-optimal bounds for generalized orthogonal Procrustes problem via generalized power method</b>.<br /> <b>S. Ling</b>, <i>Applied and Computational Harmonic Analysis</i>, 66, 62-100, 2023. <a href="https://arxiv.org/abs/2112.13725.pdf">(arXiv version)</a><a href="https://www.sciencedirect.com/science/article/pii/S1063520323000428">(Final)</a><a href="https://youtu.be/JMnJBzOugzg">(Talk Recording on Youtube)</a><a href="demo_gpm_gopp.zip">(Code demo)</a></p>
</li>
<li><p><b>Solving orthogonal group synchronization via convex and low-rank optimization: tightness and landscape analysis</b>.<br /> <b>S. Ling</b>, <i>Mathematical Programming, Series A</i>, 200, 589–628, 2023. <a href="https://arxiv.org/pdf/2006.00902.pdf">(arXiv version)</a><a href="https://link.springer.com/article/10.1007/s10107-022-01896-3">(Final)</a></p>
</li>
<li><p><b>Near-optimal performance bounds for orthogonal and permutation group synchronization via spectral methods</b>.<br /> <b>S. Ling</b>, <i>Applied and Computational Harmonic Analysis</i> 60, 20-52, 2022. <a href="https://arxiv.org/pdf/2008.05341.pdf">(arXiv version)</a><a href="https://www.sciencedirect.com/science/article/pii/S1063520322000148">(Final)</a></p>
</li>
<li><p><b>Improved performance guarantees for orthogonal group synchronization via
generalized power method</b>. <br /> <b>S. Ling</b>, <i>SIAM Journal on Optimization</i>, 32(2):1018-1048, 2022. <a href="https://arxiv.org/pdf/2012.00470.pdf">(arXiv version)</a><a href="https://epubs.siam.org/doi/abs/10.1137/20M1389571">(Final)</a></p>
</li>
<li><p><b>Strong consistency, graph Laplacians, and the stochastic block model</b>.<br /> S. Deng, <b>S. Ling</b>, T. Strohmer, <i>Journal of Machine Learning Research</i>, 22(117):1−44, 2021. <a href="https://arxiv.org/pdf/2004.09780.pdf">(arXiv version)</a><a href="https://jmlr.org/papers/v22/20-391.html">(Final)</a></p>
</li>
<li><p><b>Certifying global optimality of graph cuts via semidefinite relaxation: a performance guarantee for spectral clustering</b>.<br /> <b>S. Ling</b>, T. Strohmer, <i>Foundation of Computational Mathematics</i>, 20(3):368-421, 2020. <a href="https://arxiv.org/pdf/1806.11429.pdf">(arXiv version)</a><a href="https://link.springer.com/article/10.1007/s10208-019-09421-3">(Final)</a><a href="Slides/2018HKUST.pdf">(Slides)</a></p>
</li>
<li><p><b>When do birds of a feather flock together? k-means, proximity, and conic programming</b>.<br /> X. Li, Y. Li, <b>S. Ling</b>, T. Strohmer, K. Wei, <i>Mathematical Programming, Series A</i>, 179(1):295-341, 2020. <a href="https://arxiv.org/pdf/1710.06008.pdf">(arXiv version)</a><a href="https://link.springer.com/article/10.1007/s10107-018-1333-x">(Final)</a><a href="Slides/2018ICCHA.pdf">(Slides)</a></p>
</li>
<li><p><b>On the landscape of synchronization networks: a perspective from nonconvex optimization</b>.<br /> <b>S. Ling</b>, R. Xu, A. S. Bandeira, <i>SIAM Journal on Optimization</i>, 29(3):1879-1907, 2019. <a href="https://arxiv.org/pdf/1809.11083.pdf">(arXiv version)</a><a href="https://epubs.siam.org/doi/pdf/10.1137/18M1217644">(Final)</a><a href="http://www.birs.ca/events/2019/5-day-workshops/19w5061/videos/watch/201910281130-Ling.html">(Talk Recording at the CMO)</a></p>
</li>
<li><p><b>Rapid, robust, and reliable blind deconvolution via nonconvex optimization</b>.<br /> X. Li, <b>S. Ling</b>, T. Strohmer, K. Wei, <i>Applied and Computational Harmonic Analysis</i>, 47(3):893-934, 2019. <a href="https://arxiv.org/pdf/1606.04933.pdf">(arXiv version)</a><a href="https://www.sciencedirect.com/science/article/pii/S1063520318300149">(Final)</a><a href="Slides/2016Oaxaca.pdf">(Slides)</a><a href="http://www.birs.ca/events/2016/5-day-workshops/16w5136/videos/watch/201610181532-Ling.html">(Talk Recording at the CMO)</a></p>
</li>
<li><p><b>Regularized gradient descent: a nonconvex recipe for fast joint blind deconvolution and demixing</b>.<br /> <b>S. Ling</b>, T. Strohmer, <i>Information and Inference: A Journal of the IMA</i>, 8(1):1-49, 2019. <a href="https://arxiv.org/pdf/1703.08642.pdf">(arXiv version)</a><a href="https://academic.oup.com/imaiai/advance-article/doi/10.1093/imaiai/iax022/4924968">(Final)</a><a href="Slides/2017FOCM.pdf">(Slides)</a></p>
</li>
<li><p><b>Self-calibration and bilinear inverse problems via linear least squares</b>.<br /> <b>S. Ling</b>, T. Strohmer, <i>SIAM Journal on Imaging Sciences</i>, 11(1):252-292, 2018. <a href="https://arxiv.org/pdf/1611.04196.pdf">(arXiv)</a><a href="https://epubs.siam.org/doi/abs/10.1137/16M1103634">(Final)</a></p>
</li>
<li><p><b>Blind deconvolution meets blind demixing: algorithms and performance bounds</b>.<br /> <b>S. Ling</b>, T. Strohmer, <i>IEEE Transactions on Information Theory</i>, 63(7):4497-4520, 2017. <a href="https://arxiv.org/pdf/1512.07730.pdf">(arXiv version)</a><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7919265">(Final)</a><a href="Slides/2016Asilomar.pdf">(Slides)</a></p>
</li>
<li><p><b>Self-calibration and biconvex compressive sensing</b>.<br /> <b>S. Ling</b>, T. Strohmer, <i>Inverse Problems</i>, 31(11):115002, 2015. <a href="https://arxiv.org/pdf/1501.06864.pdf">(arXiv version)</a><a href="http://iopscience.iop.org/article/10.1088/0266-5611/31/11/115002">(Final)</a><a href="Slides/2017SIAM.pdf">(Slides)</a><br />
<a href="https://sinews.siam.org/Details-Page/prize-spotlight-shuyang-ling"><font color=red><b>(SIAM Student Paper Award 2017)</b></font></a></p>
</li>
<li><p><b>Backward error and perturbation bounds for high order Sylvester tensor equation</b>.<br /> X. Shi, Y. Wei, <b>S. Ling</b>, <i>Linear and Multilinear Algebra</i>, 61(10):1436-1446, 2013. <a href="https://www.tandfonline.com/doi/abs/10.1080/03081087.2012.743541">(Final)</a></p>
</li>
</ol>
<h2>Conference Proceedings</h2>
<ol>
<li><p><b>Fast blind deconvolution and blind demixing via nonconvex optimization</b>.<br /> <b>S.Ling</b>, T.Strohmer, <i>International Conference on Sampling Theory and Applications (SampTA)</i>, pp.114-118, 2017. <a href="https://ieeexplore.ieee.org/document/8024387/">(Final)</a></p>
</li>
<li><p><b>You can have it all &ndash; Fast algorithms for blind deconvolution, self-calibration, and demixing</b>.<br /> <b>S.Ling</b>, T.Strohmer, <i>Mathematics in Imaging</i>, MW1C.1, 2017. <a href="https://www.osapublishing.org/viewmedia.cfm?uri=MATH-2017-MW1C.1&amp;seq=0">(Final)</a></p>
</li>
<li><p><b>Simultaneous blind deconvolution and blind demixing via convex programming</b>.<br /> <b>S.Ling</b>, T.Strohmer, <i>50th Asilomar Conference on Signals, Systems and Computers</i>, pp.1223-1227, 2016. <a href="https://ieeexplore.ieee.org/document/7869568/">(Final)</a></p>
</li>
</ol>
<h2>Other publications </h2>
<ul>
<li><p><b>Bilinear Inverse Problems: Theory, Algorithms, and Applications</b>.<br /> <b>S.Ling</b>, University of California Davis, 2017, <a href="https://search.proquest.com/docview/1949289070?pq-origsite=gscholar">(Manucript)</a><a href="Slides/dissertation_ling_2017.pdf">(Slides)</a></p>
</li>
<li><p><b>Learning from their mistakes: self-calibrating sensors</b>.<br /> B. Friedlander, <b>S. Ling</b>, T. Strohmer, <i>SIAM News</i>, 52(2), 2019. <a href="https://sinews.siam.org/Details-Page/learning-from-their-mistakes-self-calibrating-sensors">(Final)</a></p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2024-12-04 08:37:08 CST, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
